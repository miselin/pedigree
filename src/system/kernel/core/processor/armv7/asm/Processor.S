# Copyright (c) 2008-2014, Pedigree Developers
# 
# Please see the CONTRIB file in the root of the source tree for a full
# list of contributors.
# 
# Permission to use, copy, modify, and distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
# 
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

# uintptr_t Processor::getBasePointer()
.global _ZN13ProcessorBase14getBasePointerEv
.type _ZN13ProcessorBase14getBasePointerEv, function
# uintptr_t Processor::getStackPointer()
.global _ZN13ProcessorBase15getStackPointerEv
.type _ZN13ProcessorBase15getStackPointerEv, function
# uintptr_t Processor::getInstructionPointer()
.global _ZN13ProcessorBase21getInstructionPointerEv
.type _ZN13ProcessorBase21getInstructionPointerEv, function
# uintptr_t Processor::getDebugStatus()
.global _ZN13ProcessorBase14getDebugStatusEv
.type _ZN13ProcessorBase14getDebugStatusEv, function

_ZN13ProcessorBase14getBasePointerEv:
  mov r0, fp
  bx lr

_ZN13ProcessorBase15getStackPointerEv:
  mov r0, sp
  bx lr

_ZN13ProcessorBase21getInstructionPointerEv:
  sub r0, lr, #4
  bx lr

# bool Processor::saveState(SchedulerState &)
.global _ZN13ProcessorBase9saveStateER19ARMV7SchedulerState
.type _ZN13ProcessorBase9saveStateER19ARMV7SchedulerState, function
# void Processor::restoreState(SchedulerState &, volatile uintptr_t *)
.global _ZN13ProcessorBase12restoreStateER19ARMV7SchedulerStatePVm
.type _ZN13ProcessorBase12restoreStateER19ARMV7SchedulerStatePVm, function
# void Processor::restoreState(volatile uintptr_t *, SyscallState &)
.global _ZN13ProcessorBase12restoreStateER17ARMV7SyscallStatePVm
.type _ZN13ProcessorBase12restoreStateER17ARMV7SyscallStatePVm, function
# void Processor::jumpKernel(volatile uintptr_t *, uintptr_t, uintptr_t,
#                            uintptr_t, uintptr_t, uintptr_t, uintptr_t)
.global _ZN13ProcessorBase10jumpKernelEPVmmmmmmm
.type _ZN13ProcessorBase10jumpKernelEPVmmmmmmm, function
# void Processor::jumpUser(volatile uintptr_t *, uintptr_t, uintptr_t,
#                          uintptr_t, uintptr_t, uintptr_t, uintptr_t)
.global _ZN13ProcessorBase8jumpUserEPVmmmmmmm
.type _ZN13ProcessorBase8jumpUserEPVmmmmmmm, function
# void PerProcessorScheduler::deleteThreadThenRestoreState(Thread*, SchedulerState&, Spinlock*)
.global _ZN21PerProcessorScheduler28deleteThreadThenRestoreStateEP6ThreadR19ARMV7SchedulerStatePVm
.type _ZN21PerProcessorScheduler28deleteThreadThenRestoreStateEP6ThreadR19ARMV7SchedulerStatePVm, function

# void Thread::threadExited()
.extern _ZN6Thread12threadExitedEv
.type _ZN6Thread12threadExitedEv, function
# void PerProcessorScheduler::deleteThread(Thread *)
.extern _ZN21PerProcessorScheduler12deleteThreadEP6Thread
.type _ZN21PerProcessorScheduler12deleteThreadEP6Thread, function

_ZN13ProcessorBase9saveStateER19ARMV7SchedulerState:
    # Store state.
    stmia r0, {r4 - r12, sp, lr}

    # Return zero - "not context restored".
    eor r0, r0
    bx lr

_ZN13ProcessorBase12restoreStateER19ARMV7SchedulerStatePVm:
    # Load state.
    ldmia r0, {r4 - r12, sp, lr}

    # Check for a passed lock, unlock if it exists
    cmp r1, #0
    beq .no_lock
    mov r0, #1
    str r0, [r1]
.no_lock:

    # Context restored, return 1.
    mov r0, #1
    bx lr

_ZN13ProcessorBase12restoreStateER17ARMV7SyscallStatePVm:
    # Load SP (== InterruptState location)
    str sp, [r0]
    
    # TODO: Save r4
    
    # Check for a passed lock, unlock if it exists
    cmp r1, #0
    beq .no_lock1
    mov r4, #1
    str r4, [r1]
.no_lock1:

    # Done.
    # TODO: Not done, gotta restore at least LR to get back to the right place
    bx lr

# void Processor::jumpKernel(volatile uintptr_t *, uintptr_t, uintptr_t,
#                            uintptr_t, uintptr_t, uintptr_t, uintptr_t)
_ZN13ProcessorBase10jumpKernelEPVmmmmmmm:
    # Note: we don't save all the registers we smash here because we're never
    # returning from this function to the caller.

    # Load parameters to pass to the new function.
    mov r4, r3
    ldr r5, [sp]
    ldr r6, [sp, #4]
    ldr r7, [sp, #8]

    # Load the new stack pointer
    cmp r2, #0
    movne sp, r2

    # Check for a passed lock, unlock if it exists
    cmp r0, #0
    beq .no_lock2
    mov r2, #1
    str r2, [r0]
.no_lock2:

    # Enable interrupts
    mrs r0, cpsr
    orr r0, r0, #0x80
    msr cpsr_c, r0

    # Return address.
    mov ip, r1

    # Load parameters for the call
    mov r0, r4
    mov r1, r5
    mov r2, r6
    mov r3, r7

    # Jump to the address - never to return
    ldr lr, =_ZN6Thread12threadExitedEv
    eor fp, fp
    bx ip

_ZN13ProcessorBase8jumpUserEPVmmmmmmm:
    bx lr

_ZN21PerProcessorScheduler28deleteThreadThenRestoreStateEP6ThreadR19ARMV7SchedulerStatePVm:
    # r0 = Thread to delete
    # r1 = New thread state
    # r2 = lock to unlock

    # Release lock if needed
    cmp r2, #0
    beq .no_lock3
    mov r3, #1
    str r3, [r2]
.no_lock3:

    # Load state, including stack pointer
    ldmia r1, {r4 - r11, r12, sp}
    mov lr, r12
   
    # Delete the thread completely (r0 preserved above)
    bl _ZN21PerProcessorScheduler12deleteThreadEP6Thread
    
    # Complete the restore
    bx lr
    
.section .init.text

.global init_stacks
.type init_stacks, function
init_stacks:
    # Read the CPSR, mask out the lower 6 bits, and enter Abort mode
    mrs r0, cpsr
    bic r0, r0, #0x3F
    orr r1, r0, #0x17
    msr cpsr_c, r1

    ldr sp, =stack_abort + 0x10000

    # Read the CPSR, mask out the lower 6 bits, and enter FIQ mode
    mrs r0, cpsr
    bic r0, r0, #0x3F
    orr r1, r0, #0x11
    msr cpsr_c, r1

    ldr sp, =stack_fiq + 0x10000

    # Read the CPSR, mask out the lower 6 bits, and enter IRQ mode
    mrs r0, cpsr
    bic r0, r0, #0x3F
    orr r1, r0, #0x12
    msr cpsr_c, r1

    # stack_irq has 0x10 bytes on top of it for saving extra data.
    ldr sp, =stack_irq + 0x10000

    # Read the CPSR, mask out the lower 6 bits, and re-enter SVC mode
    mrs r0, cpsr
    bic r0, r0, #0x3F
    orr r1, r0, #0x13
    msr cpsr_c, r1

    # Load SVC stack and go.
    ldr sp, =stack_svc + 0x20000

    bx lr

.section .stacks.irq @nobits
.align 8
# irq_save is 16 bytes at the top of the normal IRQ stack, to which scratch
# data is stored (eg, registers that we need to trash to create an IRQ frame).
.comm stack_irq, 0x10010

.section .stacks.fiq @nobits
.align 8
.comm stack_fiq, 0x10000

.section .stacks.abort @nobits
.align 8
.comm stack_abort, 0x10000

.section .stacks.svc @nobits
.align 8
.comm stack_svc, 0x20000
